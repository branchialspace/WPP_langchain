{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE7b3RDOHagcFqitCUG50G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dollabillgates/Wolfram_Physics_Project_GPT_Langchain/blob/main/Langchain_Document_Collector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sP7_ryxxiOuC"
      },
      "outputs": [],
      "source": [
        "# Get all nested urls inside an url\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        " \n",
        "urls = 'https://www.wolframphysics.org/technical-introduction/'\n",
        "grab = requests.get(urls)\n",
        "soup = BeautifulSoup(grab.text, 'html.parser')\n",
        "\n",
        "with open('wpp_Article_links.txt', 'a') as f:\n",
        "  for link in soup.find_all(\"a\"):\n",
        "    data = urljoin('https://www.wolframphysics.org', link.get('href'))\n",
        "    f.write(data)\n",
        "    f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the plain text from a list of urls\n",
        "from bs4 import BeautifulSoup \n",
        "import urllib\n",
        "\n",
        "with open('wpp_Article_links.txt', 'r') as f:\n",
        "\t\t\t\t\turls = f.readlines()\n",
        "\n",
        "with open('Wpp_Article_text.txt', 'a') as f:\n",
        "\tfor url in urls:\n",
        "\t\thtml = urllib.request.urlopen(url).read()\n",
        "\t\tsoup = BeautifulSoup(html, \"html.parser\")\n",
        "\t\tfor script in soup([\"script\", \"style\"]):\n",
        "\t\t\tscript.extract()\n",
        "\t\ttext = soup.get_text()\n",
        "\t\tf.write(text)"
      ],
      "metadata": {
        "id": "Z6bkxfg0ikfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process Text\n",
        "!grep ...... wpp_Article_text.txt > wpp_Article_textGREP1.txt # deletes lines with less than 6 characters\n",
        "!grep '[[:alnum:]]' wpp_Article_textGREP1.txt > wpp_Article_textGREP2.txt # deletes all lines without alphanumeric characters/ [[:alpha:]] for alphabetic characters\n",
        "!grep -v \"^ \" wpp_Article_textGREP2.txt > wpp_Article_textGREP3.txt # deletes all lines which start with a space (to remove indented code)\n",
        "!grep -v '^$' wpp_Article_textGREP3.txt | tr '\\n' ' ' > wpp_Article_textGREP4.txt # replaces all new lines with spaces (for langchain document loader)\n",
        "\n",
        "# Use Notepad++ for procesing (new lines in text file define the Langchain chunk overlap boundary)\n",
        "# grep commands are applied contextually/ for convenience "
      ],
      "metadata": {
        "id": "ktOWx0Ojiqem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Audio Files from Youtube\n",
        "!pip install youtube-dl\n",
        "\n",
        "!youtube-dl --extract-audio --audio-format mp3 https://youtu.be/LpK1d8mTEhI https://youtu.be/v4WytaU7q8I https://youtu.be/nSAemRxzmXM https://youtu.be/ez773teNFYA https://youtu.be/-t1_ffaFXao https://youtu.be/4-SGpEInX_c https://youtu.be/qoDZKlcdPNM https://youtu.be/1sXrRc3Bhrs"
      ],
      "metadata": {
        "id": "f94bK2PFkkCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe Audio using Whisper\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base.en\")\n",
        "result = model.transcribe(\"wolframFAU.mp3\")\n",
        "\n",
        "with open('wolframFAU.txt', 'a') as f:\n",
        "          f.write(result[\"text\"])"
      ],
      "metadata": {
        "id": "BdqAPAOUlAiu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}